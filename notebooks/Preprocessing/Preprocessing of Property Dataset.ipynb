{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d3e2d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from json import dump\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e9e994b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "properties = pd.read_json('../data/raw/property.json').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e2bbcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index count\n",
    "properties.reset_index(inplace=True)\n",
    "properties = properties.rename(columns = {'index':'URL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c12e7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand coordinates to x,y\n",
    "properties[['x','y']] = pd.DataFrame(properties.coordinates.tolist(), index= properties.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ba385d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in with all missing value with nan for further process.\n",
    "properties['Area'] = properties['Area'].replace( 0 , np.NaN)\n",
    "properties['name']  = properties['name'].replace( \"\" , np.NaN)\n",
    "properties['x']  =properties['x'].replace(0 , np.NaN)\n",
    "properties['y']  = properties['y'].replace(0 , np.NaN) \n",
    "properties['rooms'] = properties['rooms'].where(properties['rooms'].str.len() > 0, np.nan)\n",
    "properties = properties.replace(r'^\\s*$', np.NaN, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "564faf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL               0\n",
       "name              1\n",
       "cost_text         1\n",
       "type              1\n",
       "Area           9147\n",
       "coordinates       0\n",
       "rooms            19\n",
       "x                 2\n",
       "y                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the number of missing values for each attribute\n",
    "properties.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d7e2faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "# since there are too many missing values for Area variable, we decide to delete this column\n",
    "properties = properties.drop(['URL', 'Area', 'coordinates'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d96b446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "properties = properties.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e3d8fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'House': 4558,\n",
       "         'Apartment / Unit / Flat': 3839,\n",
       "         'Townhouse': 1099,\n",
       "         'Studio': 153,\n",
       "         'Duplex': 4,\n",
       "         'Villa': 22,\n",
       "         'Semi-Detached': 6,\n",
       "         'Terrace': 5,\n",
       "         'New Apartments / Off the Plan': 3,\n",
       "         'Farm': 1,\n",
       "         'Acreage / Semi-Rural': 13,\n",
       "         'Rural': 1})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for dulipication type\n",
    "Counter(properties['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d65bb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we decide to use the top five often type\n",
    "# because there are too few records for other property type\n",
    "keep_type = Counter(properties['type']).most_common(5)\n",
    "keep_type =  [item[0] for item in keep_type]\n",
    "properties = properties[properties['type'].isin(keep_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e5d8945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 7962, 2: 1709})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the structure of room for spliting.\n",
    "Counter(properties['rooms'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "547f9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split room into three attributes, indicating number of beds, baths and parking\n",
    "room_df = pd.DataFrame(properties['rooms'].tolist(), \n",
    "                        properties.index, columns=['Beds', 'Baths', 'Parking'])\n",
    "\n",
    "# Only preserve numbers and set missing to zero\n",
    "room_df = room_df.replace(r'\\D+', '', regex=True).fillna(0)\n",
    "properties = pd.concat([properties, room_df], axis=1)\n",
    "properties = properties.drop([\"rooms\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c436d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "059c0f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1157/1220037653.py:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  cost['cost_text'] = cost['cost_text'].str.lower().str.replace(\"$\",\"\").str.replace(\",\",\"\")\n"
     ]
    }
   ],
   "source": [
    "# Preprocess of cost_text attribute\n",
    "cost = properties[['cost_text']].astype({'cost_text':'string'})\n",
    "\n",
    "# Since the description of cost are human typed, there are a lot of variations\n",
    "# We inspect some data and decide to first recognise time scale using following\n",
    "WEEK_TEXT = ['per week', 'pw', 'weekly', 'p.w', 'pw.', 'wk','/w']\n",
    "MONTH_TEXT = ['per month', 'calendar month', 'pcm', '/m']\n",
    "\n",
    "cost['cost_text'] = cost['cost_text'].str.lower().str.replace(\"$\",\"\").str.replace(\",\",\"\")\n",
    "\n",
    "# The below functions recognises which time scale is each record according to\n",
    "# We need to separate them because different preprocessing method will be applied\n",
    "def containBoth(string):\n",
    "    return any(text in string for text in WEEK_TEXT) and any(text in string for text in MONTH_TEXT)\n",
    "def isWeek(string):\n",
    "    return any(text in string for text in WEEK_TEXT) and not any(text in string for text in MONTH_TEXT)\n",
    "def isMonth(string):\n",
    "    return not any(text in string for text in WEEK_TEXT) and any(text in string for text in MONTH_TEXT)\n",
    "def containNone(string):\n",
    "    return not any(text in string for text in WEEK_TEXT) and not any(text in string for text in MONTH_TEXT)\n",
    "both = cost[cost['cost_text'].apply(containBoth)]\n",
    "week = cost[cost['cost_text'].apply(isWeek)]\n",
    "month = cost[cost['cost_text'].apply(isMonth)]\n",
    "neither = cost[cost['cost_text'].apply(containNone)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bf68e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For records having both week and month cost recorded, find the 3-number digits as weekly cost\n",
    "# We are safe to do this because the minimum and maximum cost in dataframe is below 1000 and above 100\n",
    "# For simplicity, we discard the decimals because we assume this will not affect our analysis in this scale\n",
    "extractBoth = both['cost_text'].str.extract(r'(\\d{3})').astype(int)\n",
    "extractBoth.columns =['weekly_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a9ab4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For records containing weekly cost, we extract the three number digits as cost\n",
    "# We are safe to do this because the minimum and maximum cost in dataframe is below 1000 and above 100\n",
    "extractWeek = week['cost_text'].str.extract(r'(\\d{3})').fillna('-1')\n",
    "extractWeek = extractWeek.astype(int).replace(-1, np.nan)\n",
    "extractWeek.columns =['weekly_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "37149558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For records containing monthly cost, we extract the 3 OR 4 number digits as cost\n",
    "# And convert them to weekly cost\n",
    "extractMonth = month['cost_text'].apply(lambda x: re.findall(r'\\d{3}\\d?',x)).apply(min).to_frame().astype(int)\n",
    "extractMonth = extractMonth/4\n",
    "extractMonth.columns =['weekly_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b992da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For records not indicating weekly nor monthly cost, find the first 3-digit number as weekly cost\n",
    "# because the weekly cost usually appears before monthly\n",
    "extractNeither = neither['cost_text'].str.extract(r'(\\d{3})').fillna('-1')\n",
    "extractNeither = extractNeither.astype(int).replace(-1, np.nan)\n",
    "extractNeither.columns =['weekly_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c16a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine costs we preprocessed and merge them to original dataset\n",
    "costs = pd.concat([extractBoth, extractWeek, extractMonth, extractNeither])\n",
    "processed_properties = pd.merge(properties, costs, left_index=True, right_index=True)\n",
    "processed_properties = processed_properties.drop(['cost_text'], axis=1)\n",
    "processed_properties = processed_properties.dropna(subset = ['weekly_cost'])\n",
    "processed_properties = processed_properties.drop_duplicates(subset = ['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c48fa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the coordinate attributes\n",
    "processed_properties = processed_properties.rename(columns={\"x\": \"prop_lat\", \"y\" : \"prop_long\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e0881100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, since we need to make analysis group by suburb, we need to extract suburb from each address\n",
    "# We want to first find the street type of address, (e.g road, street, way), and the section after it should be suburb\n",
    "# However, due to the humantarian input, it is extremely complicated because the length of suburb varies\n",
    "# We first scrap all possible street suffixes from website\n",
    "url = \"https://en.wikipedia.org/wiki/Street_suffix\"\n",
    "street_metadata = defaultdict(dict)\n",
    "bs_object = BeautifulSoup(requests.get(url).text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98aef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_street = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d586a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in bs_object.find_all('ul'):\n",
    "    world_street.append(li.text)\n",
    "australia_street = world_street[8].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2c5d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9f79e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for street in australia_street:\n",
    "    process = street[: street.find('\\t')].split()\n",
    "    for each in process:\n",
    "        suffix.append(each.strip('()').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "72d64499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some street name will make confusion to suffix\n",
    "# This will be regularly update if problem happens\n",
    "suffix.remove('wharf')\n",
    "suffix.remove('entrance')\n",
    "suffix.remove('square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c0d10888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert every string to lowercase for consistency\n",
    "processed_properties[\"name\"] = processed_properties[\"name\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "83f2a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep those addresses with suffix in it\n",
    "processed_properties = processed_properties[processed_properties[\"name\"] \\\n",
    "                                            .apply(lambda x: any(string in x.split() for string in suffix)) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6888d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that suburbs only made of at most 3 words, therefore the last four items will always contain suburb\n",
    "# since there are very few of them\n",
    "\n",
    "# extract the part of name that may contain suburb\n",
    "processed_properties['suburb'] = processed_properties['name'].apply(lambda x: x.split()[-5:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "59b1578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter suburbs made with three words by checking the first item is a street suffix\n",
    "processed_properties['suburb'] = processed_properties['suburb'] \\\n",
    "            .apply(lambda x: x[1:] if x[0] in suffix else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b8bf7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter suburbs made with two words by checking the second item is a street suffix\n",
    "# the rest will be suburb made with one word\n",
    "processed_properties['suburb'] = processed_properties['suburb'] \\\n",
    "            .apply(lambda x: x[2:] if len(x)>=2 and x[1] in suffix else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0668745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_properties['suburb'] = processed_properties['suburb'] \\\n",
    "            .apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d1ca9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_properties = processed_properties[processed_properties['suburb'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "525c7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_properties.to_csv('../data/curated/properties.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57dc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
